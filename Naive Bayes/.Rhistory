d <- read.csv(file.choose(),stringsAsFactors = F)
View(d)
library(ggplot2)
ggplot(d,aes(sales,profit))+
geom_point()
#Q3 ----
#Acquiring the data
TG_data <- ToothGrowth
View(TG_data)
#Loading necessary libraries ----
library(dplyr)   #for transforming data and contains pipe operator
library(tm)   #tm: text mining library is used for text cleaning
library(SnowballC)   #Library for stemming
library(caret)    #Library for splitting data
library(e1071)   #package for NaiveBayes
library(gmodels)  #library for crosstable for confusionmatrix
#Loading the data ----
mail_Data <- read.csv(file = "spam.csv",stringsAsFactors = F)
setwd("C:/Users/arvbr/OneDrive/Documents/GitHub/Predictive-Analysis/Naive Bayes")
#Observing the data ----
str(mail_Data)
table(mail_Data$type)
#cleaning and transforming the data ----
#Removing unnecessary columns &
#converting label into categorical variable which makes it easy for classification
mail_Data <- mail_Data[,c("type","text")]
#Data Preprocessing ----
#text cleaning in this data set
mail_corpus <- iconv(mail_Data$text, to = "UTF-8", sub = "")
mail_corpus_clean<-  Corpus(VectorSource(mail_corpus))%>%
tm_map(content_transformer(tolower))%>%
tm_map(removeNumbers)%>%
tm_map(removePunctuation)%>%
tm_map(removeWords,stopwords("en"))%>%
tm_map(stripWhitespace)%>%
tm_map(stemDocument)
mail_Data$type <- as.factor(mail_Data$type)
trainIndex <- createDataPartition(mail_Data$type, p = 0.8, list = F)
#Splitting the data ----
set.seed(123)
#DTM
mail_dtm <- DocumentTermMatrix(mail_corpus_clean)
mail_train_data <- mail_dtm[trainIndex, ]
mail_test_data <- mail_dtm[-trainIndex, ]
mail_train_labels <- mail_Data$type[trainIndex]
mail_test_labels <- mail_Data$type[-trainIndex]
#Loading the data ----
mail_Data <- read.csv(file = "spam.csv",stringsAsFactors = F)
#Observing the data ----
str(mail_Data)
table(mail_Data$type)
mail_Data$type <- as.factor(mail_Data$type)
#cleaning and transforming the data ----
#Removing unnecessary columns &
#converting label into categorical variable which makes it easy for classification
mail_Data <- mail_Data[,c("type","text")]
#Data Preprocessing ----
#text cleaning in this data set
mail_corpus <- iconv(mail_Data$text, to = "UTF-8", sub = "")
mail_corpus_clean<-  Corpus(VectorSource(mail_corpus))%>%
tm_map(content_transformer(tolower))%>%
tm_map(removeNumbers)%>%
tm_map(removePunctuation)%>%
tm_map(removeWords,stopwords("en"))%>%
tm_map(stripWhitespace)%>%
tm_map(stemDocument)
#DTM
mail_dtm <- DocumentTermMatrix(mail_corpus_clean)
#Splitting the data ----
set.seed(123)
mail_train_data <- mail_dtm[trainIndex, ]
trainIndex <- createDataPartition(mail_Data$type, p = 0.8, list = F)
mail_test_data <- mail_dtm[-trainIndex, ]
mail_train_labels <- mail_Data$type[trainIndex]
mail_test_labels <- mail_Data$type[-trainIndex]
mail_train_data <- mail_dtm[trainIndex, ]
#Training the model ----
model <- naiveBayes(as.matrix(mail_train_data),mail_train_labels)
predictions <- predict(model,as.matrix(mail_test_data))
#Evaluating ----
confusionMatrix(predictions,mail_test_labels)
CrossTable(predictions,mail_test_labels,prop.chisq = F)
mail_train_data <- as.matrix(mail_train_data)
mail_test_data <- as.matrix(mail_test_data)
library(wordcloud)
View(mail_train_data)
#
wordcloud(mail_corpus_clean,min.freq = 50,
random.order = F,colors = brewer.pal(5,"Dark2"))
#Wordcloud ----
wordcloud(mail_corpus_clean,min.freq = 60,
random.order = F,colors = brewer.pal(5,"Dark2"))
#Wordcloud ----
wordcloud(mail_corpus_clean,min.freq = 20,
random.order = F,colors = brewer.pal(5,"Dark2"))
#Wordcloud ----
wordcloud(mail_corpus_clean,min.freq = 50,
random.order = F,colors = brewer.pal(5,"Dark2"))
#Wordcloud ----
wordcloud(mail_corpus_clean,min.freq = 100,
random.order = F,colors = brewer.pal(5,"Dark2"))
#Wordcloud ----
wordcloud(mail_corpus_clean,min.freq = 10,
random.order = F,colors = brewer.pal(5,"Dark2"))
#Wordcloud ----
wordcloud(mail_corpus_clean,min.freq = 0.5,
random.order = F,colors = brewer.pal(5,"Dark2"))
#Wordcloud ----
wordcloud(mail_corpus_clean,min.freq = 1,
random.order = F,colors = brewer.pal(5,"Dark2"))
#Observing the data ----
str(mail_Data)
table(mail_Data$type)
#cleaning and transforming the data ----
#Removing unnecessary columns &
#converting label into categorical variable which makes it easy for classification
mail_Data <- mail_Data[,c("type","text")]
mail_Data$type <- as.factor(mail_Data$type)
#Data Preprocessing ----
#text cleaning in this data set
mail_corpus <- iconv(mail_Data$text)
mail_corpus_clean<-  Corpus(VectorSource(mail_corpus))%>%
tm_map(content_transformer(tolower))%>%
tm_map(removeNumbers)%>%
tm_map(removePunctuation)%>%
tm_map(removeWords,stopwords("en"))%>%
tm_map(stripWhitespace)%>%
tm_map(stemDocument)
#DTM
mail_dtm <- DocumentTermMatrix(mail_corpus_clean)
#Splitting the data ----
set.seed(123)
trainIndex <- createDataPartition(mail_Data$type, p = 0.8, list = F)
mail_train_data <- mail_dtm[trainIndex, ]
mail_test_data <- mail_dtm[-trainIndex, ]
mail_train_labels <- mail_Data$type[trainIndex]
mail_test_labels <- mail_Data$type[-trainIndex]
mail_train_data <- as.matrix(mail_train_data)
mail_test_data <- as.matrix(mail_test_data)
#Wordcloud ----
wordcloud(mail_corpus_clean,min.freq = 1,
random.order = F,colors = brewer.pal(5,"Dark2"))
findFreqTerms(mail_train_data,5)
gc()
gc()
#Loading the data ----
mail_Data <- read.csv(file = "spam.csv",stringsAsFactors = F)
#Observing the data ----
str(mail_Data)
table(mail_Data$type)
#cleaning and transforming the data ----
#Removing unnecessary columns &
#converting label into categorical variable which makes it easy for classification
mail_Data <- mail_Data[,c("type","text")]
mail_Data$type <- as.factor(mail_Data$type)
#Data Preprocessing ----
#text cleaning in this data set
mail_corpus <- iconv(mail_Data$text)
mail_corpus_clean<-  Corpus(VectorSource(mail_corpus))%>%
tm_map(content_transformer(tolower))%>%
tm_map(removeNumbers)%>%
tm_map(removePunctuation)%>%
tm_map(removeWords,stopwords("en"))%>%
tm_map(stripWhitespace)%>%
tm_map(stemDocument)
#DTM
mail_dtm <- DocumentTermMatrix(mail_corpus_clean)
#Splitting the data ----
set.seed(123)
trainIndex <- createDataPartition(mail_Data$type, p = 0.8, list = F)
mail_train_data <- mail_dtm[trainIndex, ]
mail_test_data <- mail_dtm[-trainIndex, ]
mail_train_labels <- mail_Data$type[trainIndex]
mail_test_labels <- mail_Data$type[-trainIndex]
#Wordcloud ----
wordcloud(mail_corpus_clean,min.freq = 50,
random.order = F,colors = brewer.pal(5,"Dark2"))
findFreqTerms(mail_train_data,5)
mail_freq_words <- findFreqTerms(mail_train_data, 5)
str(mail_freq_words)
mail_freq_train<- mail_train_data[ , mail_freq_words]
mail_freq_test <- mail_test_data[ , mail_freq_words]
#Training the model ----
model <- naiveBayes(mail_freq_train,mail_train_labels)
View(mail_freq_train)
View(mail_train_data)
#Training the model ----
model <- naiveBayes(as.matrix(mail_freq_train),mail_train_labels)
predictions <- predict(model,as.matriz(mail_test_data))
predictions <- predict(model,as.matrix(mail_test_data))
#Evaluating ----
confusionMatrix(predictions,mail_test_labels)
CrossTable(predictions,mail_test_labels,prop.chisq = F)
gc()
#loading data ----
sms_raw <- read.csv(file = "spam.csv", stringsAsFactors = FALSE)
#Cleaning  ----
sms_raw$type <- factor(sms_raw$type)
sms_raw <- sms_raw[,c("type","text")]
sms_corpus<-iconv(sms_raw$text)
sms_corpus <- Corpus(VectorSource(sms_corpus))
print(sms_corpus)
inspect(sms_corpus[1:2])
as.character(sms_corpus[[1]])
lapply(sms_corpus[1:2], as.character)
#Loading necessary libraries ----
library(dplyr)   #for transforming data and contains pipe operator
library(tm)   #tm: text mining library is used for text cleaning
sms_corpus_clean <- tm_map(sms_corpus,content_transformer(tolower))
as.character(sms_corpus[[1]])
as.character(sms_corpus_clean[[1]])
gc()
gc()
gc()
gc()
#Cleaning  ----
sms_raw$type <- factor(sms_raw$type)
sms_raw <- sms_raw[,c("type","text")]
#Text Cleaning: ----
library(tm)
sms_corpus<-iconv(sms_raw$text)
sms_corpus <- Corpus(VectorSource(sms_corpus))
lapply(sms_corpus[1:2], as.character)
#loading data ----
sms_raw <- read.csv(file = "spam.csv", stringsAsFactors = FALSE)
#Cleaning  ----
sms_raw$type <- factor(sms_raw$type)
sms_raw <- sms_raw[,c("type","text")]
#Text Cleaning: ----
library(tm)
sms_corpus<-iconv(sms_raw$text)
sms_corpus <- Corpus(VectorSource(sms_corpus))
lapply(sms_corpus[1:2], as.character)
sms_corpus_clean <- tm_map(sms_corpus,content_transformer(tolower))%>%
tm_map(removeNumbers)%>%
tm_map(removeWords, stopwords())%>%
tm_map(sms_corpus_clean, removePunctuation)
sms_corpus_clean
sms_corpus_clean <- tm_map(sms_corpus,content_transformer(tolower))%>%
tm_map(removeNumbers)%>%
tm_map(removeWords, stopwords())%>%
tm_map(sms_corpus_clean, removePunctuation)
View(sms_corpus)
sms_corpus[1:2]
#loading data ----
sms_raw <- read.csv(file = "spam.csv", stringsAsFactors = FALSE)
#Cleaning  ----
sms_raw$type <- factor(sms_raw$type)
sms_raw <- sms_raw[,c("type","text")]
#Text Cleaning: ----
library(tm)
sms_corpus<-iconv(sms_raw$text)
sms_corpus <- Corpus(VectorSource(sms_corpus))%>%
lapply(as.character)
#loading data ----
sms_raw <- read.csv(file = "spam.csv", stringsAsFactors = FALSE)
#Cleaning  ----
sms_raw$type <- factor(sms_raw$type)
sms_raw <- sms_raw[,c("type","text")]
#Text Cleaning: ----
library(tm)
sms_corpus<-iconv(sms_raw$text)
sms_corpus <- Corpus(VectorSource(sms_corpus))%>%
lapply(as.character)%>%
tm_map(sms_corpus,content_transformer(tolower))%>%
tm_map(removeNumbers)%>%
tm_map(removeWords, stopwords())%>%
tm_map(sms_corpus_clean, removePunctuation)
lapply(sms_corpus[1:2], as.character)
#loading data ----
sms_raw <- read.csv(file = "spam.csv", stringsAsFactors = FALSE)
#Cleaning  ----
sms_raw$type <- factor(sms_raw$type)
sms_raw <- sms_raw[,c("type","text")]
#Text Cleaning: ----
library(tm)
sms_corpus<-iconv(sms_raw$text)
sms_corpus <- Corpus(VectorSource(sms_corpus))%>%
tm_map(sms_corpus,content_transformer(tolower))%>%
tm_map(removeNumbers)%>%
tm_map(removeWords, stopwords())%>%
tm_map(sms_corpus_clean, removePunctuation)
sms_corpus_clean <- Corpus(VectorSource(sms_corpus))%>%
tm_map(sms_corpus,content_transformer(tolower))%>%
tm_map(removeNumbers)%>%
tm_map(removeWords, stopwords())%>%
tm_map(sms_corpus_clean, removePunctuation)
#Text Cleaning: ----
library(tm)
sms_corpus<-iconv(sms_raw$text)
sms_corpus_clean <- Corpus(VectorSource(sms_corpus))%>%
tm_map(sms_corpus,content_transformer(tolower))%>%
tm_map(removeNumbers)%>%
tm_map(removeWords, stopwords())%>%
tm_map(sms_corpus_clean, removePunctuation)
sms_corpus_clean <- Corpus(VectorSource(sms_corpus))%>%
tm_map(content_transformer(tolower))%>%
tm_map(removeNumbers)%>%
tm_map(removeWords, stopwords())%>%
tm_map(sms_corpus_clean, removePunctuation)
sms_corpus %>% Corpus(VectorSource())%>%
tm_map(content_transformer(tolower))%>%
tm_map(removeNumbers)%>%
tm_map(removeWords, stopwords())%>%
tm_map(sms_corpus_clean, removePunctuation) -> sms_corpus_clean
sms_corpus_clean <- Corpus(VectorSource(sms_corpus))%>%
tm_map(content_transformer(tolower))%>%
tm_map(removeNumbers)%>%
tm_map(removeWords, stopwords())%>%
tm_map(sms_corpus_clean, removePunctuation)
#Loading the data ----
mail_Data <- read.csv(file = "spam.csv",stringsAsFactors = F)
#Observing the data ----
str(mail_Data)
table(mail_Data$type)
#cleaning and transforming the data ----
#Removing unnecessary columns &
#converting label into categorical variable which makes it easy for classification
mail_Data <- mail_Data[,c("type","text")]
mail_Data$type <- as.factor(mail_Data$type)
#Data Preprocessing ----
#text cleaning in this data set
mail_corpus <- iconv(mail_Data$text)
mail_corpus_clean<-  Corpus(VectorSource(mail_corpus))%>%
tm_map(content_transformer(tolower))%>%
tm_map(removeNumbers)%>%
tm_map(removePunctuation)%>%
tm_map(removeWords,stopwords())%>%
tm_map(stripWhitespace)%>%
tm_map(stemDocument)
sms_corpus_clean <- Corpus(VectorSource(sms_corpus))%>%
tm_map(content_transformer(tolower))%>%
tm_map(removeNumbers)%>%
tm_map(removeWords, stopwords())%>%
tm_map(sms_corpus_clean, removePunctuation)%>%
tm_map(stemDocument)
